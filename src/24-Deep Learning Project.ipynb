{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Proyecto Tutorial de Clasficador de Imagenes"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "El conjunto de datos se compone de fotos de perros y gatos proporcionadas como un subconjunto de fotos de uno mucho más grande de 3 millones de fotos anotadas manualmente."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Importar librerías necesarias\n",
                "\n",
                "from tensorflow import keras\n",
                "import keras,os\n",
                "from keras.models import Sequential\n",
                "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
                "from keras.preprocessing.image import ImageDataGenerator\n",
                "import numpy as np"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [
                {
                    "ename": "FileNotFoundError",
                    "evalue": "[Errno 2] No such file or directory: './train'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[29], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Use the ImageDataGenerator to load the data\u001b[39;00m\n\u001b[1;32m      3\u001b[0m trdata \u001b[39m=\u001b[39m ImageDataGenerator()\n\u001b[0;32m----> 4\u001b[0m traindata \u001b[39m=\u001b[39m trdata\u001b[39m.\u001b[39;49mflow_from_directory(directory\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m./train\u001b[39;49m\u001b[39m\"\u001b[39;49m,target_size\u001b[39m=\u001b[39;49m(\u001b[39m200\u001b[39;49m,\u001b[39m200\u001b[39;49m))\n\u001b[1;32m      5\u001b[0m tsdata \u001b[39m=\u001b[39m ImageDataGenerator()\n\u001b[1;32m      6\u001b[0m testdata \u001b[39m=\u001b[39m tsdata\u001b[39m.\u001b[39mflow_from_directory(directory\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./test1\u001b[39m\u001b[39m\"\u001b[39m, target_size\u001b[39m=\u001b[39m(\u001b[39m200\u001b[39m,\u001b[39m200\u001b[39m))\n",
                        "File \u001b[0;32m~/.local/lib/python3.11/site-packages/keras/src/preprocessing/image.py:1648\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1562\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflow_from_directory\u001b[39m(\n\u001b[1;32m   1563\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1564\u001b[0m     directory,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1578\u001b[0m     keep_aspect_ratio\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   1579\u001b[0m ):\n\u001b[1;32m   1580\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Takes the path to a directory & generates batches of augmented data.\u001b[39;00m\n\u001b[1;32m   1581\u001b[0m \n\u001b[1;32m   1582\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1646\u001b[0m \u001b[39m            and `y` is a numpy array of corresponding labels.\u001b[39;00m\n\u001b[1;32m   1647\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1648\u001b[0m     \u001b[39mreturn\u001b[39;00m DirectoryIterator(\n\u001b[1;32m   1649\u001b[0m         directory,\n\u001b[1;32m   1650\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1651\u001b[0m         target_size\u001b[39m=\u001b[39;49mtarget_size,\n\u001b[1;32m   1652\u001b[0m         color_mode\u001b[39m=\u001b[39;49mcolor_mode,\n\u001b[1;32m   1653\u001b[0m         keep_aspect_ratio\u001b[39m=\u001b[39;49mkeep_aspect_ratio,\n\u001b[1;32m   1654\u001b[0m         classes\u001b[39m=\u001b[39;49mclasses,\n\u001b[1;32m   1655\u001b[0m         class_mode\u001b[39m=\u001b[39;49mclass_mode,\n\u001b[1;32m   1656\u001b[0m         data_format\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_format,\n\u001b[1;32m   1657\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   1658\u001b[0m         shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m   1659\u001b[0m         seed\u001b[39m=\u001b[39;49mseed,\n\u001b[1;32m   1660\u001b[0m         save_to_dir\u001b[39m=\u001b[39;49msave_to_dir,\n\u001b[1;32m   1661\u001b[0m         save_prefix\u001b[39m=\u001b[39;49msave_prefix,\n\u001b[1;32m   1662\u001b[0m         save_format\u001b[39m=\u001b[39;49msave_format,\n\u001b[1;32m   1663\u001b[0m         follow_links\u001b[39m=\u001b[39;49mfollow_links,\n\u001b[1;32m   1664\u001b[0m         subset\u001b[39m=\u001b[39;49msubset,\n\u001b[1;32m   1665\u001b[0m         interpolation\u001b[39m=\u001b[39;49minterpolation,\n\u001b[1;32m   1666\u001b[0m         dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype,\n\u001b[1;32m   1667\u001b[0m     )\n",
                        "File \u001b[0;32m~/.local/lib/python3.11/site-packages/keras/src/preprocessing/image.py:563\u001b[0m, in \u001b[0;36mDirectoryIterator.__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m classes:\n\u001b[1;32m    562\u001b[0m     classes \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 563\u001b[0m     \u001b[39mfor\u001b[39;00m subdir \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(os\u001b[39m.\u001b[39mlistdir(directory)):\n\u001b[1;32m    564\u001b[0m         \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(directory, subdir)):\n\u001b[1;32m    565\u001b[0m             classes\u001b[39m.\u001b[39mappend(subdir)\n",
                        "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './train'"
                    ]
                }
            ],
            "source": [
                "# Use the ImageDataGenerator to load the data\n",
                "\n",
                "trdata = ImageDataGenerator()\n",
                "traindata = trdata.flow_from_directory(directory=\"/workspaces/ml-template/train\",target_size=(200,200))\n",
                "tsdata = ImageDataGenerator()\n",
                "testdata = tsdata.flow_from_directory(directory=\"/workspaces/ml-template/test1\", target_size=(200,200))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Pass the data to the neural network\n",
                "\n",
                "model = Sequential()\n",
                "model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
                "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
                "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
                "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
                "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
                "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
                "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
                "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
                "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
                "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
                "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
                "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
                "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
                "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
                "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
                "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
                "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
                "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Pass the data to the dense layer\n",
                "\n",
                "model.add(Flatten())\n",
                "model.add(Dense(units=4096,activation=\"relu\"))\n",
                "model.add(Dense(units=4096,activation=\"relu\"))\n",
                "model.add(Dense(units=2, activation=\"softmax\"))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
                    ]
                }
            ],
            "source": [
                "# Compile the model\n",
                "\n",
                "from keras.optimizers import Adam\n",
                "opt = Adam(lr=0.001)\n",
                "model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model: \"sequential\"\n",
                        "_________________________________________________________________\n",
                        " Layer (type)                Output Shape              Param #   \n",
                        "=================================================================\n",
                        " conv2d (Conv2D)             (None, 224, 224, 64)      1792      \n",
                        "                                                                 \n",
                        " conv2d_1 (Conv2D)           (None, 224, 224, 64)      36928     \n",
                        "                                                                 \n",
                        " max_pooling2d (MaxPooling2  (None, 112, 112, 64)      0         \n",
                        " D)                                                              \n",
                        "                                                                 \n",
                        " conv2d_2 (Conv2D)           (None, 112, 112, 128)     73856     \n",
                        "                                                                 \n",
                        " conv2d_3 (Conv2D)           (None, 112, 112, 128)     147584    \n",
                        "                                                                 \n",
                        " max_pooling2d_1 (MaxPoolin  (None, 56, 56, 128)       0         \n",
                        " g2D)                                                            \n",
                        "                                                                 \n",
                        " conv2d_4 (Conv2D)           (None, 56, 56, 256)       295168    \n",
                        "                                                                 \n",
                        " conv2d_5 (Conv2D)           (None, 56, 56, 256)       590080    \n",
                        "                                                                 \n",
                        " conv2d_6 (Conv2D)           (None, 56, 56, 256)       590080    \n",
                        "                                                                 \n",
                        " max_pooling2d_2 (MaxPoolin  (None, 28, 28, 256)       0         \n",
                        " g2D)                                                            \n",
                        "                                                                 \n",
                        " conv2d_7 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
                        "                                                                 \n",
                        " conv2d_8 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
                        "                                                                 \n",
                        " conv2d_9 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
                        "                                                                 \n",
                        " max_pooling2d_3 (MaxPoolin  (None, 14, 14, 512)       0         \n",
                        " g2D)                                                            \n",
                        "                                                                 \n",
                        " conv2d_10 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
                        "                                                                 \n",
                        " conv2d_11 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
                        "                                                                 \n",
                        " conv2d_12 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
                        "                                                                 \n",
                        " max_pooling2d_4 (MaxPoolin  (None, 7, 7, 512)         0         \n",
                        " g2D)                                                            \n",
                        "                                                                 \n",
                        " flatten (Flatten)           (None, 25088)             0         \n",
                        "                                                                 \n",
                        " dense (Dense)               (None, 4096)              102764544 \n",
                        "                                                                 \n",
                        " dense_1 (Dense)             (None, 4096)              16781312  \n",
                        "                                                                 \n",
                        " dense_2 (Dense)             (None, 2)                 8194      \n",
                        "                                                                 \n",
                        "=================================================================\n",
                        "Total params: 134268738 (512.19 MB)\n",
                        "Trainable params: 134268738 (512.19 MB)\n",
                        "Non-trainable params: 0 (0.00 Byte)\n",
                        "_________________________________________________________________\n"
                    ]
                }
            ],
            "source": [
                "# Get the model summary\n",
                "\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
                        "/tmp/ipykernel_629/2260461392.py:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
                        "  hist = model.fit_generator(steps_per_epoch=100,generator=traindata, validation_data= testdata, validation_steps=10,epochs=100,callbacks=[checkpoint,early])\n"
                    ]
                },
                {
                    "ename": "ValueError",
                    "evalue": "Asked to retrieve element 0, but the Sequence has length 0",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[28], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m checkpoint \u001b[39m=\u001b[39m ModelCheckpoint(\u001b[39m\"\u001b[39m\u001b[39mvgg16_1.h5\u001b[39m\u001b[39m\"\u001b[39m, monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_acc\u001b[39m\u001b[39m'\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, save_weights_only\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m, period\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m early \u001b[39m=\u001b[39m EarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_acc\u001b[39m\u001b[39m'\u001b[39m, min_delta\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m hist \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit_generator(steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,generator\u001b[39m=\u001b[39;49mtraindata, validation_data\u001b[39m=\u001b[39;49m testdata, validation_steps\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,callbacks\u001b[39m=\u001b[39;49m[checkpoint,early])\n",
                        "File \u001b[0;32m~/.local/lib/python3.11/site-packages/keras/src/engine/training.py:2810\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2798\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[1;32m   2799\u001b[0m \n\u001b[1;32m   2800\u001b[0m \u001b[39mDEPRECATED:\u001b[39;00m\n\u001b[1;32m   2801\u001b[0m \u001b[39m  `Model.fit` now supports generators, so there is no longer any need to\u001b[39;00m\n\u001b[1;32m   2802\u001b[0m \u001b[39m  use this endpoint.\u001b[39;00m\n\u001b[1;32m   2803\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2804\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   2805\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m`Model.fit_generator` is deprecated and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2806\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mwill be removed in a future version. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2807\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2808\u001b[0m     stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m   2809\u001b[0m )\n\u001b[0;32m-> 2810\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m   2811\u001b[0m     generator,\n\u001b[1;32m   2812\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m   2813\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m   2814\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   2815\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   2816\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[1;32m   2817\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[1;32m   2818\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[1;32m   2819\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[1;32m   2820\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   2821\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   2822\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   2823\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m   2824\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[1;32m   2825\u001b[0m )\n",
                        "File \u001b[0;32m~/.local/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
                        "File \u001b[0;32m~/.local/lib/python3.11/site-packages/keras/src/preprocessing/image.py:103\u001b[0m, in \u001b[0;36mIterator.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[1;32m    102\u001b[0m     \u001b[39mif\u001b[39;00m idx \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 103\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    104\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mAsked to retrieve element \u001b[39m\u001b[39m{idx}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    105\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mbut the Sequence \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    106\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mhas length \u001b[39m\u001b[39m{length}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(idx\u001b[39m=\u001b[39midx, length\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m))\n\u001b[1;32m    107\u001b[0m         )\n\u001b[1;32m    108\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseed \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    109\u001b[0m         np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mseed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseed \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal_batches_seen)\n",
                        "\u001b[0;31mValueError\u001b[0m: Asked to retrieve element 0, but the Sequence has length 0"
                    ]
                }
            ],
            "source": [
                "# Create objects for ModelCheckpoint and EarlyStopping, and pass them as callback functions to fit_generator\n",
                "\n",
                "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
                "checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
                "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')\n",
                "hist = model.fit_generator(steps_per_epoch=100,generator=traindata, validation_data= testdata, validation_steps=10,epochs=100,callbacks=[checkpoint,early])"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.13 64-bit ('3.8.13')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.4"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
